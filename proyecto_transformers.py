# -*- coding: utf-8 -*-
"""PRoyecto_Transformers.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TjiilnNhyGscHcJokN7ugqhx5tJEtImo
"""

"""Proyecto_Transformers_Optimizado.ipynb

An√°lisis de emociones optimizado con m√∫ltiples mejoras
"""

!pip install transformers scikit-learn torch imbalanced-learn optuna

import pandas as pd
import numpy as np
from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification
import torch
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.preprocessing import label_binarize
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import optuna
from collections import Counter
warnings.filterwarnings('ignore')

# Load the dataset
df = pd.read_csv('Nuevo_Dataset_Patrones_Emocionales.csv')

def emocion_para_columna(col):
    """Asocia cada pregunta con su emoci√≥n correspondiente"""
    pregunta_numero = int(col.split('.')[0])
    if pregunta_numero in [1, 2]:
        return 'Felicidad'
    elif pregunta_numero in [3, 4]:
        return 'Tristeza'
    elif pregunta_numero in [5, 6]:
        return 'Disgusto'
    elif pregunta_numero in [7, 8]:
        return 'Ira'
    elif pregunta_numero in [9, 10]:
        return 'Miedo'
    elif pregunta_numero in [11, 12]:
        return 'Sorpresa'
    return None

# An√°lisis exploratorio de datos mejorado
def analizar_datos(df):
    """Realiza un an√°lisis detallado del dataset"""
    print("="*60)
    print("AN√ÅLISIS EXPLORATORIO DE DATOS")
    print("="*60)

    preguntas_reales = [col for col in df.columns if col.strip()[0].isdigit()]
    print(f"N√∫mero de preguntas encontradas: {len(preguntas_reales)}")
    print(f"Preguntas: {preguntas_reales[:5]}...")  # Mostrar primeras 5

    # Crear dataset de respuestas
    data_respuestas = pd.DataFrame()
    for pregunta in preguntas_reales:
        emocion = emocion_para_columna(pregunta)
        temp_df = pd.DataFrame({
            'Pregunta': [pregunta] * len(df),
            'Respuesta': df[pregunta],
            'Emocion': [emocion] * len(df)
        })
        data_respuestas = pd.concat([data_respuestas, temp_df], ignore_index=True)

    # Limpieza inicial
    print(f"\nAntes de limpieza: {len(data_respuestas)} respuestas")
    data_respuestas = data_respuestas.dropna(subset=['Respuesta'])
    data_respuestas = data_respuestas[data_respuestas['Respuesta'].str.strip() != '']
    print(f"Despu√©s de limpieza: {len(data_respuestas)} respuestas")

    # An√°lisis de distribuci√≥n
    print(f"\nDistribuci√≥n de emociones:")
    distribucion = data_respuestas['Emocion'].value_counts()
    print(distribucion)

    # Calcular ratio de desbalance
    max_count = distribucion.max()
    min_count = distribucion.min()
    ratio_desbalance = max_count / min_count
    print(f"\nRatio de desbalance: {ratio_desbalance:.2f}")

    if ratio_desbalance > 2:
        print("‚ö†Ô∏è  Dataset desbalanceado detectado - se aplicar√° balanceo")

    # An√°lisis de longitud de respuestas
    data_respuestas['longitud'] = data_respuestas['Respuesta'].str.len()
    print(f"\nEstad√≠sticas de longitud de respuestas:")
    print(f"Media: {data_respuestas['longitud'].mean():.1f} caracteres")
    print(f"Mediana: {data_respuestas['longitud'].median():.1f} caracteres")
    print(f"Min: {data_respuestas['longitud'].min()} - Max: {data_respuestas['longitud'].max()}")

    return data_respuestas

# An√°lisis del dataset
data_respuestas_con_emociones = analizar_datos(df)

# Funci√≥n mejorada para cargar modelos
def load_model_safely(model_names):
    """Intenta cargar modelos con mejor manejo de errores"""
    for i, model_name in enumerate(model_names, 1):
        try:
            print(f"Intentando cargar modelo {i}: {model_name}")
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModel.from_pretrained(model_name)
            print(f"‚úÖ Modelo cargado exitosamente: {model_name}")
            return tokenizer, model, model_name
        except Exception as e:
            print(f"‚ùå Error con {model_name}: {str(e)[:100]}...")
            continue

    print("‚ùå No se pudo cargar ning√∫n modelo")
    return None, None, None

# Lista ampliada de modelos
models_to_try = [
    "pysentimiento/robertuito-base-cased",
    "dccuchile/bert-base-spanish-wwm-cased",
    "cardiffnlp/twitter-roberta-base-emotion-multilingual",
    "xlm-roberta-base",
    "distilbert-base-multilingual-cased"
]

tokenizer, model, selected_model = load_model_safely(models_to_try)

if tokenizer is None:
    print("No se pudo cargar ning√∫n modelo. Verificar conexi√≥n a internet.")
    exit()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando device: {device}")
model.to(device)

# Function to generate embeddings (Simple version as backup)
def generate_embeddings_simple(texts, tokenizer, model, device, batch_size=16):
    """Versi√≥n simplificada que solo usa mean pooling"""
    embeddings = []
    model.eval()

    with torch.no_grad():
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            encoded_input = tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                return_tensors='pt',
                max_length=128  # Reducido para mayor compatibilidad
            )

            input_ids = encoded_input['input_ids'].to(device)
            attention_mask = encoded_input['attention_mask'].to(device)

            outputs = model(input_ids, attention_mask=attention_mask)
            last_hidden_states = outputs.last_hidden_state

            # Solo mean pooling para evitar problems de dimensiones
            attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_states.size()).float()
            masked_embeddings = last_hidden_states * attention_mask_expanded
            sum_embeddings = torch.sum(masked_embeddings, 1)
            sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)
            mean_pooled = sum_embeddings / sum_mask

            embeddings.extend(mean_pooled.cpu().numpy())

    return np.array(embeddings)

def generate_embeddings_advanced(texts, tokenizer, model, device, batch_size=16, max_length=256):
    """Generaci√≥n de embeddings con m√∫ltiples estrategias de pooling - versi√≥n corregida"""
    embeddings = []
    model.eval()

    with torch.no_grad():
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            encoded_input = tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                return_tensors='pt',
                max_length=max_length
            )

            input_ids = encoded_input['input_ids'].to(device)
            attention_mask = encoded_input['attention_mask'].to(device)
            # Note: We are NOT explicitly providing token_type_ids here.
            # The model might generate them internally, and this is where the error potentially lies.
            # Keeping the advanced logic as is for now, but moving the simple function definition.

            outputs = model(input_ids, attention_mask=attention_mask)
            last_hidden_states = outputs.last_hidden_state

            # Obtener dimensiones correctas
            batch_size_actual = last_hidden_states.size(0)
            seq_length = last_hidden_states.size(1)
            hidden_size = last_hidden_states.size(2)

            # Expandir m√°scara de atenci√≥n correctamente
            attention_mask_expanded = attention_mask.unsqueeze(-1).expand(batch_size_actual, seq_length, hidden_size).float()

            # 1. Mean pooling (promedio ponderado)
            masked_embeddings = last_hidden_states * attention_mask_expanded
            sum_embeddings = torch.sum(masked_embeddings, 1)
            sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)
            mean_pooled = sum_embeddings / sum_mask

            # 2. Max pooling
            masked_embeddings_max = last_hidden_states.clone()
            masked_embeddings_max[attention_mask_expanded == 0] = -1e9
            max_pooled = torch.max(masked_embeddings_max, 1)[0]

            # 3. CLS token (primer token)
            cls_embeddings = last_hidden_states[:, 0, :]

            # Concatenar diferentes tipos de pooling para mayor riqueza
            # Verify dimensions before concatenating - this was helpful for debugging
            # print(f"Debug - Mean pooled shape: {mean_pooled.shape}")
            # print(f"Debug - Max pooled shape: {max_pooled.shape}")
            # print(f"Debug - CLS embeddings shape: {cls_embeddings.shape}")

            combined_embeddings = torch.cat([mean_pooled, max_pooled, cls_embeddings], dim=1)

            embeddings.extend(combined_embeddings.cpu().numpy())

    return np.array(embeddings)


print("Generando embeddings avanzados...")
respuestas_texto = data_respuestas_con_emociones['Respuesta'].fillna('').astype(str).tolist()

# Primero intentamos con embeddings avanzados, si falla usamos simples
try:
    print("Intentando con embeddings avanzados (triple pooling)...")
    # Probar con a batch first to see if it works
    text_embeddings = generate_embeddings_advanced(respuestas_texto[:16], tokenizer, model, device)
    print("‚úÖ Embeddings avanzados funcionan correctamente con un batch")
    # If the test batch works, process the full data
    text_embeddings = generate_embeddings_advanced(respuestas_texto, tokenizer, model, device)
    use_advanced = True
except Exception as e:
    print(f"‚ùå Error con embeddings avanzados: {e}")
    print("üîÑ Cambiando a embeddings simples...")
    # The generate_embeddings_simple function is now defined above
    text_embeddings = generate_embeddings_simple(respuestas_texto, tokenizer, model, device)
    use_advanced = False

print(f"Embeddings generados: {text_embeddings.shape}")
print(f"Tipo de embedding usado: {'Avanzado (triple pooling)' if use_advanced else 'Simple (mean pooling)'}")

# Preparaci√≥n de datos mejorada
label_encoder = LabelEncoder()
emociones_texto = data_respuestas_con_emociones['Emocion'].fillna('').astype(str).tolist()
encoded_labels = label_encoder.fit_transform(emociones_texto)

# Normalizaci√≥n de features
scaler = StandardScaler()
text_embeddings_scaled = scaler.fit_transform(text_embeddings)

# Divisi√≥n estratificada
X_train, X_test, y_train, y_test = train_test_split(
    text_embeddings_scaled,
    encoded_labels,
    test_size=0.2,
    random_state=42,
    stratify=encoded_labels
)

print(f"Conjunto de entrenamiento: {X_train.shape}")
print(f"Conjunto de prueba: {X_test.shape}")

# An√°lisis de desbalance y aplicaci√≥n de SMOTE
def aplicar_balanceo(X_train, y_train):
    """Aplica t√©cnicas de balanceo de clases"""
    print("\n" + "="*50)
    print("BALANCEO DE CLASES")
    print("="*50)

    # Contar clases antes del balanceo
    counter_before = Counter(y_train)
    print("Distribuci√≥n antes del balanceo:")
    for clase, count in counter_before.items():
        print(f"  {label_encoder.inverse_transform([clase])[0]}: {count}")

    # Aplicar SMOTE para sobremuestreo
    # Ensure k_neighbors is less than or equal to the number of samples in the minority class minus 1
    min_samples_minority = min(counter_before.values())
    k_neighbors_smote = min(5, min_samples_minority - 1) if min_samples_minority > 1 else 0

    if k_neighbors_smote > 0:
        smote = SMOTE(random_state=42, k_neighbors=k_neighbors_smote)
        X_balanced, y_balanced = smote.fit_resample(X_train, y_train)
        # Contar clases despu√©s del balanceo
        counter_after = Counter(y_balanced)
        print("\nDistribuci√≥n despu√©s del balanceo:")
        for clase, count in counter_after.items():
            print(f"  {label_encoder.inverse_transform([clase])[0]}: {count}")
    else:
        print("\nSkipping SMOTE: Not enough samples in minority class for oversampling.")
        X_balanced, y_balanced = X_train, y_train


    return X_balanced, y_balanced

X_train_balanced, y_train_balanced = aplicar_balanceo(X_train, y_train)

# Optimizaci√≥n de hiperpar√°metros con Optuna
def optimize_classifier(X_train, y_train, X_test, y_test, n_trials=50):
    """Optimiza hiperpar√°metros usando Optuna"""

    def objective(trial):
        # Sugerir tipo de clasificador
        classifier_name = trial.suggest_categorical('classifier', ['logistic', 'svm', 'rf', 'gb'])

        if classifier_name == 'logistic':
            C = trial.suggest_float('C', 1e-3, 1e3, log=True)
            max_iter = trial.suggest_int('max_iter', 500, 2000)
            solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs'])
            classifier = LogisticRegression(C=C, max_iter=max_iter, solver=solver, random_state=42)

        elif classifier_name == 'svm':
            C = trial.suggest_float('svm_C', 1e-3, 1e3, log=True)
            gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])
            kernel = trial.suggest_categorical('kernel', ['rbf', 'linear'])
            classifier = SVC(C=C, gamma=gamma, kernel=kernel, probability=True, random_state=42)

        elif classifier_name == 'rf':
            n_estimators = trial.suggest_int('n_estimators', 50, 300)
            max_depth = trial.suggest_int('max_depth', 5, 20)
            min_samples_split = trial.suggest_int('min_samples_split', 2, 10)
            classifier = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                random_state=42
            )

        else:  # gradient boosting
            n_estimators = trial.suggest_int('gb_n_estimators', 50, 200)
            learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)
            max_depth = trial.suggest_int('gb_max_depth', 3, 10)
            classifier = GradientBoostingClassifier(
                n_estimators=n_estimators,
                learning_rate=learning_rate,
                max_depth=max_depth,
                random_state=42
            )

        # Validaci√≥n cruzada
        # Ensure there's more than one class for scoring
        if len(np.unique(y_train)) > 1:
            cv_scores = cross_val_score(classifier, X_train, y_train, cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42), scoring='f1_weighted')
            return cv_scores.mean()
        else:
             # If only one class, return a low value so Optuna doesn't favor this
            return -1.0


    print("\n" + "="*50)
    print("OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS")
    print("="*50)

    study = optuna.create_study(direction='maximize')
    # Check if there's more than one class before optimizing
    if len(np.unique(y_train)) > 1:
        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

        print(f"Mejor F1 score en validaci√≥n cruzada: {study.best_value:.4f}")
        print(f"Mejores par√°metros: {study.best_params}")

        return study.best_params
    else:
        print("Skipping Optuna: Only one class present after balanceo.")
        # Return default parameters or handle accordingly
        return {'classifier': 'logistic', 'C': 1.0, 'max_iter': 1000, 'solver': 'lbfgs'} # Example defaults

# Ejecutar optimizaci√≥n (reducir n_trials si es muy lento)
best_params = optimize_classifier(X_train_balanced, y_train_balanced, X_test, y_test, n_trials=10) # Reduced trials for faster execution

# Entrenar el mejor modelo
def train_best_model(best_params, X_train, y_train):
    """Entrena el modelo con los mejores par√°metros"""
    classifier_name = best_params['classifier']

    if classifier_name == 'logistic':
        classifier = LogisticRegression(
            C=best_params.get('C', 1.0), # Use .get for robustness
            max_iter=best_params.get('max_iter', 1000),
            solver=best_params.get('solver', 'lbfgs'),
            random_state=42
        )
    elif classifier_name == 'svm':
        classifier = SVC(
            C=best_params.get('svm_C', 1.0),
            gamma=best_params.get('gamma', 'scale'),
            kernel=best_params.get('kernel', 'rbf'),
            probability=True,
            random_state=42
        )
    elif classifier_name == 'rf':
        classifier = RandomForestClassifier(
            n_estimators=best_params.get('n_estimators', 100),
            max_depth=best_params.get('max_depth', 10),
            min_samples_split=best_params.get('min_samples_split', 2),
            random_state=42
        )
    else:  # gradient boosting
        classifier = GradientBoostingClassifier(
            n_estimators=best_params.get('gb_n_estimators', 100),
            learning_rate=best_params.get('learning_rate', 0.1),
            max_depth=best_params.get('gb_max_depth', 3),
            random_state=42
        )

    # Ensure training happens only if there's data
    if X_train.shape[0] > 0:
         classifier.fit(X_train, y_train)
    else:
        print("Skipping model training: Training data is empty.")
        classifier = None # Or handle appropriately

    return classifier

best_classifier = train_best_model(best_params, X_train_balanced, y_train_balanced)

# Evaluation section should only run if best_classifier is not None
if best_classifier is not None:
    # Evaluaci√≥n completa
    print("\n" + "="*50)
    print("EVALUACI√ìN DEL MODELO OPTIMIZADO")
    print("="*50)

    # Ensure y_test is not empty before predicting
    if X_test.shape[0] > 0:
        y_pred = best_classifier.predict(X_test)
        y_prob = best_classifier.predict_proba(X_test)

        # M√©tricas detalladas
        accuracy = accuracy_score(y_test, y_pred)
        f1_weighted = f1_score(y_test, y_pred, average='weighted')
        f1_macro = f1_score(y_test, y_pred, average='macro')
        recall_weighted = recall_score(y_test, y_pred, average='weighted')
        recall_macro = recall_score(y_test, y_pred, average='macro')

        # ROC-AUC requires probabilities and multiple classes
        try:
            if len(np.unique(y_test)) > 1 and y_prob.shape[1] > 1:
                roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')
            else:
                roc_auc = np.nan # Not applicable for single class or binary probas in multi-class scenario
        except Exception as e:
            print(f"Could not calculate ROC-AUC. Error: {e}")
            roc_auc = np.nan

        print(f"Modelo utilizado: {selected_model}")
        print(f"Clasificador: {best_params['classifier']}")
        print(f"\nM√âTRICAS:")
        print(f"Accuracy: {accuracy:.4f}")
        print(f"F1 Score (Weighted): {f1_weighted:.4f}")
        print(f"F1 Score (Macro): {f1_macro:.4f}")
        print(f"Recall (Weighted): {recall_weighted:.4f}")
        print(f"Recall (Macro): {recall_macro:.4f}")
        if not np.isnan(roc_auc):
            print(f"ROC-AUC: {roc_auc:.4f}")

        # Reporte de clasificaci√≥n detallado
        print(f"\nREPORTE DE CLASIFICACI√ìN DETALLADO:")
        print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

        # Matriz de confusi√≥n mejorada
        conf_matrix = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(12, 10))
        sns.heatmap(
            conf_matrix,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_,
            cbar_kws={'label': 'N√∫mero de muestras'}
        )
        plt.xlabel('Etiqueta Predicha', fontsize=12)
        plt.ylabel('Etiqueta Verdadera', fontsize=12)
        plt.title(f'Matriz de Confusi√≥n Optimizada\nModelo: {selected_model} | Clasificador: {best_params["classifier"]}', fontsize=14)
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.show()

        # An√°lisis de errores por clase
        print(f"\nAN√ÅLISIS DE ERRORES POR CLASE:")
        for i, clase in enumerate(label_encoder.classes_):
            mask = y_test == i
            if mask.sum() > 0:
                accuracy_clase = accuracy_score(y_test[mask], y_pred[mask])
                print(f"{clase}: {accuracy_clase:.3f} ({mask.sum()} muestras)")
    else:
        print("Skipping evaluation: Test data is empty.")

# Funci√≥n de predicci√≥n mejorada - versi√≥n corregida
def predict_emotion_advanced(text, tokenizer, model, classifier, label_encoder, scaler, device):
    """Funci√≥n de predicci√≥n mejorada con el modelo optimizado - versi√≥n corregida"""
    if classifier is None:
         return {'emocion': 'Modelo no entrenado', 'confianza': 0.0, 'probabilidades': {}}

    if not text or text.strip() == '':
        return {'emocion': 'Texto vac√≠o', 'confianza': 0.0, 'probabilidades': {}}

    # Generar embedding usando la same function based on use_advanced flag
    # Note: This function now calls the simple one to avoid the advanced pooling complexity if needed.
    # If use_advanced is True, it would ideally call the advanced one, but we simplified here for robustness.
    text_embedding = generate_embeddings_simple([text], tokenizer, model, device)
    text_embedding_scaled = scaler.transform(text_embedding)

    # Predecir
    # Ensure classifier can handle predict_proba (SVC needs probability=True)
    if hasattr(classifier, 'predict_proba'):
         predicted_proba = classifier.predict_proba(text_embedding_scaled)[0]
         predicted_label = classifier.predict(text_embedding_scaled)[0]
         confidence = predicted_proba.max()

         # Probabilities by class
         probabilidades = {}
         for i, emocion in enumerate(label_encoder.classes_):
             probabilidades[emocion] = predicted_proba[i]
    else:
        # Fallback if predict_proba is not available (e.g., certain SVC configs)
        predicted_label = classifier.predict(text_embedding_scaled)[0]
        confidence = 1.0 # Assume high confidence if no proba
        probabilidades = {label_encoder.inverse_transform([predicted_label])[0]: 1.0} # Only the predicted class

    # Decode
    predicted_emotion = label_encoder.inverse_transform([predicted_label])[0]


    return {
        'emocion': predicted_emotion,
        'confianza': confidence,
        'probabilidades': probabilidades
    }


# Ejemplos de predicci√≥n con el modelo optimizado
print("\n" + "="*50)
print("EJEMPLOS CON MODELO OPTIMIZADO")
print("="*50)

textos_ejemplo = [
    "¬°Estoy s√∫per feliz! Hoy consegu√≠ el trabajo de mis sue√±os",
    "Me siento muy triste y melanc√≥lico, como si nada tuviera sentido",
    "¬°No puedo creer lo que acaba de pasar! ¬°Qu√© sorpresa incre√≠ble!",
    "Estoy furioso, esto es completamente inaceptable e injusto",
    "Tengo p√°nico, no s√© qu√© va a pasar y estoy muy nervioso",
    "Esta situaci√≥n me da mucho asco, es repugnante"
]

# Only run examples if the model was successfully trained
if best_classifier is not None:
    for texto in textos_ejemplo:
        try:
            # Always use the predict_emotion_advanced function, which internally calls the simple embedding one
            # or handles the advanced one based on the success/failure during training data processing.
            # Given the RuntimeError on advanced, we should ensure the simple embedding is used here for prediction.
            # The predict_emotion_advanced function was modified to call generate_embeddings_simple
            resultado = predict_emotion_advanced(texto, tokenizer, model, best_classifier, label_encoder, scaler, device)

            print(f"\nTexto: '{texto}'")
            print(f"Emoci√≥n: {resultado['emocion']} (confianza: {resultado['confianza']:.3f})")

            # Top 2 probabilities
            prob_sorted = sorted(resultado['probabilidades'].items(), key=lambda x: x[1], reverse=True)
            print("Probabilidades:")
            for emocion, prob in prob_sorted[:2]:
                print(f"  {emocion}: {prob:.3f}")
        except Exception as e:
            print(f"Error prediciendo '{texto}': {e}")
else:
    print("Skipping prediction examples: Model training failed.")


print("\n" + "="*60)
print("OPTIMIZACI√ìN COMPLETADA")
print("="*60)

"""Nuevo intento

En 15 minutos
"""

# OPTIMIZACI√ìN R√ÅPIDA - VERSI√ìN 15 MINUTOS
# Prioriza velocidad manteniendo buena calidad

import time

def fast_svm_optimization(X_train, y_train, X_test, y_test, label_encoder):
    """Optimizaci√≥n r√°pida de SVM - completada en ~15 minutos"""

    print("\n" + "="*60)
    print("üöÄ OPTIMIZACI√ìN SVM R√ÅPIDA (15 MINUTOS)")
    print("="*60)

    start_total = time.time()

    # 1. PREPROCESAMIENTO LIGERO (1-2 minutos)
    print("‚è≥ Preprocesamiento ligero...")
    start_time = time.time()

    # Solo normalizaci√≥n robusta (m√°s r√°pida que PCA completo)
    from sklearn.preprocessing import RobustScaler
    scaler = RobustScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    print(f"‚úÖ Preprocesamiento: {time.time() - start_time:.1f}s")

    # 2. GRID SEARCH DIRIGIDO (3-5 minutos)
    print("‚è≥ Optimizaci√≥n dirigida de hiperpar√°metros...")
    start_time = time.time()

    # Par√°metros pre-seleccionados basados en experiencia
    from sklearn.model_selection import GridSearchCV

    param_grids = {
        'rbf': {
            'kernel': ['rbf'],
            'C': [0.1, 1.0, 10.0],  # Solo 3 valores en lugar de b√∫squeda logar√≠tmica
            'gamma': ['scale', 0.001, 0.01]  # Solo 3 valores
        },
        'linear': {
            'kernel': ['linear'],
            'C': [0.1, 1.0, 10.0]
        },
        'poly': {
            'kernel': ['poly'],
            'degree': [2, 3],  # Solo grados 2 y 3
            'C': [0.1, 1.0, 10.0],
            'gamma': ['scale']
        }
    }

    best_models = {}

    for kernel_name, param_grid in param_grids.items():
        print(f"  üîç Optimizando SVM {kernel_name.upper()}...")

        svm = SVC(probability=True, random_state=42)

        # Grid search con solo 3-fold CV para velocidad
        grid_search = GridSearchCV(
            svm, param_grid,
            cv=3,  # Reducido de 5 a 3 para velocidad
            scoring='f1_weighted',
            n_jobs=-1  # Paralelizaci√≥n
        )

        grid_search.fit(X_train_scaled, y_train)
        best_models[kernel_name] = {
            'model': grid_search.best_estimator_,
            'score': grid_search.best_score_,
            'params': grid_search.best_params_
        }

        print(f"    Mejor score: {grid_search.best_score_:.4f}")

    print(f"‚úÖ Optimizaci√≥n: {time.time() - start_time:.1f}s")

    # 3. EVALUACI√ìN R√ÅPIDA DE CANDIDATOS (2-3 minutos)
    print("‚è≥ Evaluando modelos candidatos...")
    start_time = time.time()

    # Agregar modelos b√°sicos r√°pidos
    quick_models = {
        'logistic': LogisticRegression(C=1.0, max_iter=1000, random_state=42),
        'rf_fast': RandomForestClassifier(n_estimators=50, random_state=42)  # Menos √°rboles
    }

    all_results = {}

    # Evaluar modelos SVM optimizados
    for name, info in best_models.items():
        model = info['model']
        y_pred = model.predict(X_test_scaled)

        all_results[f'svm_{name}'] = {
            'model': model,
            'accuracy': accuracy_score(y_test, y_pred),
            'f1_weighted': f1_score(y_test, y_pred, average='weighted'),
            'f1_macro': f1_score(y_test, y_pred, average='macro'),
            'params': info['params']
        }

        print(f"  SVM {name.upper()}: {all_results[f'svm_{name}']['accuracy']:.4f} accuracy")

    # Evaluar modelos r√°pidos
    for name, model in quick_models.items():
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)

        all_results[name] = {
            'model': model,
            'accuracy': accuracy_score(y_test, y_pred),
            'f1_weighted': f1_score(y_test, y_pred, average='weighted'),
            'f1_macro': f1_score(y_test, y_pred, average='macro')
        }

        print(f"  {name.upper()}: {all_results[name]['accuracy']:.4f} accuracy")

    print(f"‚úÖ Evaluaci√≥n: {time.time() - start_time:.1f}s")

    # 4. SELECCI√ìN DEL MEJOR Y ENSAMBLE LIGERO (2-3 minutos)
    print("‚è≥ Creando ensamble ligero...")
    start_time = time.time()

    # Seleccionar top 3 modelos para ensamble
    sorted_models = sorted(all_results.items(),
                          key=lambda x: x[1]['f1_weighted'],
                          reverse=True)

    top_3_models = [item[1]['model'] for item in sorted_models[:3]]

    # Ensamble ligero con solo top 3
    from sklearn.ensemble import VotingClassifier
    ensemble = VotingClassifier(
        estimators=[(f'model_{i}', model) for i, model in enumerate(top_3_models)],
        voting='soft'
    )

    ensemble.fit(X_train_scaled, y_train)
    y_pred_ensemble = ensemble.predict(X_test_scaled)

    ensemble_results = {
        'accuracy': accuracy_score(y_test, y_pred_ensemble),
        'f1_weighted': f1_score(y_test, y_pred_ensemble, average='weighted'),
        'f1_macro': f1_score(y_test, y_pred_ensemble, average='macro')
    }

    print(f"‚úÖ Ensamble: {time.time() - start_time:.1f}s")

    # RESULTADOS FINALES
    total_time = time.time() - start_total

    print("\n" + "="*60)
    print("üéØ RESULTADOS FINALES")
    print("="*60)

    print(f"‚è±Ô∏è  Tiempo total: {total_time/60:.1f} minutos")
    print()

    print("üìä RANKING DE MODELOS:")
    for i, (name, results) in enumerate(sorted_models, 1):
        print(f"{i}. {name.upper()}")
        print(f"   Accuracy: {results['accuracy']:.4f}")
        print(f"   F1 Weighted: {results['f1_weighted']:.4f}")
        if 'params' in results:
            print(f"   Par√°metros: {results['params']}")
        print()

    print("üèÜ ENSAMBLE (TOP 3):")
    print(f"   Accuracy: {ensemble_results['accuracy']:.4f}")
    print(f"   F1 Weighted: {ensemble_results['f1_weighted']:.4f}")
    print(f"   F1 Macro: {ensemble_results['f1_macro']:.4f}")

    # Comparaci√≥n con resultado original
    original_accuracy = 0.6320
    best_single = sorted_models[0][1]['accuracy']
    best_ensemble = ensemble_results['accuracy']

    print("\n" + "="*50)
    print("üìà MEJORAS OBTENIDAS:")
    print("="*50)
    print(f"Modelo original: {original_accuracy:.4f} ({original_accuracy*100:.1f}%)")
    print(f"Mejor individual: {best_single:.4f} ({best_single*100:.1f}%) [+{(best_single-original_accuracy)*100:.1f}%]")
    print(f"Mejor ensamble: {best_ensemble:.4f} ({best_ensemble*100:.1f}%) [+{(best_ensemble-original_accuracy)*100:.1f}%]")

    return {
        'best_individual': sorted_models[0],
        'ensemble_model': ensemble,
        'ensemble_results': ensemble_results,
        'all_results': all_results,
        'scaler': scaler,
        'total_time': total_time
    }

# C√ìDIGO PARA EJECUTAR EN TU SCRIPT
print("Iniciando optimizaci√≥n r√°pida...")
print("‚è±Ô∏è Tiempo estimado: 10-15 minutos")

# Ejecutar optimizaci√≥n
results = fast_svm_optimization(
    X_train_balanced, y_train_balanced,
    X_test, y_test, label_encoder
)

# Funci√≥n de predicci√≥n actualizada para el mejor modelo
def predict_with_best_model(text, tokenizer, model, best_results, device):
    """Predicci√≥n con el mejor modelo encontrado"""

    if not text or text.strip() == '':
        return {'emocion': 'Texto vac√≠o', 'confianza': 0.0}

    # Generar embedding
    text_embedding = generate_embeddings_simple([text], tokenizer, model, device)

    # Aplicar mismo preprocesamiento
    scaler = best_results['scaler']
    text_embedding_scaled = scaler.transform(text_embedding)

    # Usar el mejor modelo (ensamble o individual)
    best_model = best_results['ensemble_model']

    predicted_proba = best_model.predict_proba(text_embedding_scaled)[0]
    predicted_label = best_model.predict(text_embedding_scaled)[0]

    predicted_emotion = label_encoder.inverse_transform([predicted_label])[0]
    confidence = predicted_proba.max()

    return {
        'emocion': predicted_emotion,
        'confianza': confidence,
        'probabilidades': {
            label_encoder.classes_[i]: prob
            for i, prob in enumerate(predicted_proba)
        }
    }

# Probar con ejemplos
print("\n" + "="*50)
print("üß™ PRUEBAS CON MODELO OPTIMIZADO")
print("="*50)

textos_prueba = [
    "¬°Estoy s√∫per feliz! Hoy consegu√≠ el trabajo de mis sue√±os",
    "Me siento muy triste y melanc√≥lico, como si nada tuviera sentido",
    "¬°No puedo creer lo que acaba de pasar! ¬°Qu√© sorpresa incre√≠ble!",
    "Estoy furioso, esto es completamente inaceptable"
]

for texto in textos_prueba:
    resultado = predict_with_best_model(texto, tokenizer, model, results, device)
    print(f"\nTexto: '{texto[:50]}...'")
    print(f"Emoci√≥n: {resultado['emocion']} (confianza: {resultado['confianza']:.3f})")

print("\nüéâ Optimizaci√≥n completada!")
print(f"‚è±Ô∏è Tiempo total: {results['total_time']/60:.1f} minutos")

"""Proyecto_Transformers_Optimizado.ipynb

An√°lisis de emociones optimizado con m√∫ltiples mejoras
"""

!pip install transformers scikit-learn torch imbalanced-learn optuna

import pandas as pd
import numpy as np
from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification
import torch
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.preprocessing import label_binarize
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import optuna
from collections import Counter
import time # Added the missing import for time
warnings.filterwarnings('ignore')

# Load the dataset
df = pd.read_csv('Nuevo_Dataset_Patrones_Emocionales.csv')

def emocion_para_columna(col):
    """Asocia cada pregunta con su emoci√≥n correspondiente"""
    pregunta_numero = int(col.split('.')[0])
    if pregunta_numero in [1, 2]:
        return 'Felicidad'
    elif pregunta_numero in [3, 4]:
        return 'Tristeza'
    elif pregunta_numero in [5, 6]:
        return 'Disgusto'
    elif pregunta_numero in [7, 8]:
        return 'Ira'
    elif pregunta_numero in [9, 10]:
        return 'Miedo'
    elif pregunta_numero in [11, 12]:
        return 'Sorpresa'
    return None

# An√°lisis exploratorio de datos mejorado
def analizar_datos(df):
    """Realiza un an√°lisis detallado del dataset"""
    print("="*60)
    print("AN√ÅLISIS EXPLORATORIO DE DATOS")
    print("="*60)

    preguntas_reales = [col for col in df.columns if col.strip()[0].isdigit()]
    print(f"N√∫mero de preguntas encontradas: {len(preguntas_reales)}")
    print(f"Preguntas: {preguntas_reales[:5]}...")  # Mostrar primeras 5

    # Crear dataset de respuestas
    data_respuestas = pd.DataFrame()
    for pregunta in preguntas_reales:
        emocion = emocion_para_columna(pregunta)
        temp_df = pd.DataFrame({
            'Pregunta': [pregunta] * len(df),
            'Respuesta': df[pregunta],
            'Emocion': [emocion] * len(df)
        })
        data_respuestas = pd.concat([data_respuestas, temp_df], ignore_index=True)

    # Limpieza inicial
    print(f"\nAntes de limpieza: {len(data_respuestas)} respuestas")
    data_respuestas = data_respuestas.dropna(subset=['Respuesta'])
    data_respuestas = data_respuestas[data_respuestas['Respuesta'].str.strip() != '']
    print(f"Despu√©s de limpieza: {len(data_respuestas)} respuestas")

    # An√°lisis de distribuci√≥n
    print(f"\nDistribuci√≥n de emociones:")
    distribucion = data_respuestas['Emocion'].value_counts()
    print(distribucion)

    # Calcular ratio de desbalance
    max_count = distribucion.max()
    min_count = distribucion.min()
    ratio_desbalance = max_count / min_count
    print(f"\nRatio de desbalance: {ratio_desbalance:.2f}")

    if ratio_desbalance > 2:
        print("‚ö†Ô∏è  Dataset desbalanceado detectado - se aplicar√° balanceo")

    # An√°lisis de longitud de respuestas
    data_respuestas['longitud'] = data_respuestas['Respuesta'].str.len()
    print(f"\nEstad√≠sticas de longitud de respuestas:")
    print(f"Media: {data_respuestas['longitud'].mean():.1f} caracteres")
    print(f"Mediana: {data_respuestas['longitud'].median():.1f} caracteres")
    print(f"Min: {data_respuestas['longitud'].min()} - Max: {data_respuestas['longitud'].max()}")

    return data_respuestas

# An√°lisis del dataset
data_respuestas_con_emociones = analizar_datos(df)

# Funci√≥n mejorada para cargar modelos
def load_model_safely(model_names):
    """Intenta cargar modelos con mejor manejo de errores"""
    for i, model_name in enumerate(model_names, 1):
        try:
            print(f"Intentando cargar modelo {i}: {model_name}")
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModel.from_pretrained(model_name)
            print(f"‚úÖ Modelo cargado exitosamente: {model_name}")
            return tokenizer, model, model_name
        except Exception as e:
            print(f"‚ùå Error con {model_name}: {str(e)[:100]}...")
            continue

    print("‚ùå No se pudo cargar ning√∫n modelo")
    return None, None, None

# Lista ampliada de modelos
models_to_try = [
    "pysentimiento/robertuito-base-cased",
    "dccuchile/bert-base-spanish-wwm-cased",
    "cardiffnlp/twitter-roberta-base-emotion-multilingual",
    "xlm-roberta-base",
    "distilbert-base-multilingual-cased"
]

tokenizer, model, selected_model = load_model_safely(models_to_try)

if tokenizer is None:
    print("No se pudo cargar ning√∫n modelo. Verificar conexi√≥n a internet.")
    exit()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando device: {device}")
model.to(device)

# Function to generate embeddings (Simple version as backup)
def generate_embeddings_simple(texts, tokenizer, model, device, batch_size=16):
    """Versi√≥n simplificada que solo usa mean pooling"""
    embeddings = []
    model.eval()

    with torch.no_grad():
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            encoded_input = tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                return_tensors='pt',
                max_length=128  # Reducido para mayor compatibilidad
            )

            input_ids = encoded_input['input_ids'].to(device)
            attention_mask = encoded_input['attention_mask'].to(device)

            outputs = model(input_ids, attention_mask=attention_mask)
            last_hidden_states = outputs.last_hidden_state

            # Solo mean pooling para evitar problems de dimensiones
            attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_states.size()).float()
            masked_embeddings = last_hidden_states * attention_mask_expanded
            sum_embeddings = torch.sum(masked_embeddings, 1)
            sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)
            mean_pooled = sum_embeddings / sum_mask

            embeddings.extend(mean_pooled.cpu().numpy())

    return np.array(embeddings)

def generate_embeddings_advanced(texts, tokenizer, model, device, batch_size=16, max_length=256):
    """Generaci√≥n de embeddings con m√∫ltiples estrategias de pooling - versi√≥n corregida"""
    embeddings = []
    model.eval()

    with torch.no_grad():
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            encoded_input = tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                return_tensors='pt',
                max_length=max_length
            )

            input_ids = encoded_input['input_ids'].to(device)
            attention_mask = encoded_input['attention_mask'].to(device)
            # Note: We are NOT explicitly providing token_type_ids here.
            # The model might generate them internally, and this is where the error potentially lies.
            # Keeping the advanced logic as is for now, but moving the simple function definition.

            outputs = model(input_ids, attention_mask=attention_mask)
            last_hidden_states = outputs.last_hidden_state

            # Obtener dimensiones correctas
            batch_size_actual = last_hidden_states.size(0)
            seq_length = last_hidden_states.size(1)
            hidden_size = last_hidden_states.size(2)

            # Expandir m√°scara de atenci√≥n correctamente
            attention_mask_expanded = attention_mask.unsqueeze(-1).expand(batch_size_actual, seq_length, hidden_size).float()

            # 1. Mean pooling (promedio ponderado)
            masked_embeddings = last_hidden_states * attention_mask_expanded
            sum_embeddings = torch.sum(masked_embeddings, 1)
            sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)
            mean_pooled = sum_embeddings / sum_mask

            # 2. Max pooling
            masked_embeddings_max = last_hidden_states.clone()
            masked_embeddings_max[attention_mask_expanded == 0] = -1e9
            max_pooled = torch.max(masked_embeddings_max, 1)[0]

            # 3. CLS token (primer token)
            cls_embeddings = last_hidden_states[:, 0, :]

            # Concatenar diferentes tipos de pooling para mayor riqueza
            # Verify dimensions before concatenating - this was helpful for debugging
            # print(f"Debug - Mean pooled shape: {mean_pooled.shape}")
            # print(f"Debug - Max pooled shape: {max_pooled.shape}")
            # print(f"Debug - CLS embeddings shape: {cls_embeddings.shape}")

            combined_embeddings = torch.cat([mean_pooled, max_pooled, cls_embeddings], dim=1)

            embeddings.extend(combined_embeddings.cpu().numpy())

    return np.array(embeddings)


print("Generando embeddings avanzados...")
respuestas_texto = data_respuestas_con_emociones['Respuesta'].fillna('').astype(str).tolist()

# Primero intentamos con embeddings avanzados, si falla usamos simples
try:
    print("Intentando con embeddings avanzados (triple pooling)...")
    # Probar con a batch first to see if it works
    text_embeddings = generate_embeddings_advanced(respuestas_texto[:16], tokenizer, model, device)
    print("‚úÖ Embeddings avanzados funcionan correctamente con un batch")
    # If the test batch works, process the full data
    text_embeddings = generate_embeddings_advanced(respuestas_texto, tokenizer, model, device)
    use_advanced = True
except Exception as e:
    print(f"‚ùå Error con embeddings avanzados: {e}")
    print("üîÑ Cambiando a embeddings simples...")
    # The generate_embeddings_simple function is now defined above
    text_embeddings = generate_embeddings_simple(respuestas_texto, tokenizer, model, device)
    use_advanced = False

print(f"Embeddings generados: {text_embeddings.shape}")
print(f"Tipo de embedding usado: {'Avanzado (triple pooling)' if use_advanced else 'Simple (mean pooling)'}")

# Preparaci√≥n de datos mejorada
label_encoder = LabelEncoder()
emociones_texto = data_respuestas_con_emociones['Emocion'].fillna('').astype(str).tolist()
encoded_labels = label_encoder.fit_transform(emociones_texto)

# Normalizaci√≥n de features
scaler = StandardScaler()
text_embeddings_scaled = scaler.fit_transform(text_embeddings)

# Divisi√≥n estratificada
X_train, X_test, y_train, y_test = train_test_split(
    text_embeddings_scaled,
    encoded_labels,
    test_size=0.2,
    random_state=42,
    stratify=encoded_labels
)

print(f"Conjunto de entrenamiento: {X_train.shape}")
print(f"Conjunto de prueba: {X_test.shape}")

# An√°lisis de desbalance y aplicaci√≥n de SMOTE
def aplicar_balanceo(X_train, y_train):
    """Aplica t√©cnicas de balanceo de clases"""
    print("\n" + "="*50)
    print("BALANCEO DE CLASES")
    print("="*50)

    # Contar clases antes del balanceo
    counter_before = Counter(y_train)
    print("Distribuci√≥n antes del balanceo:")
    for clase, count in counter_before.items():
        print(f"  {label_encoder.inverse_transform([clase])[0]}: {count}")

    # Aplicar SMOTE para sobremuestreo
    # Ensure k_neighbors is less than or equal to the number of samples in the minority class minus 1
    min_samples_minority = min(counter_before.values())
    k_neighbors_smote = min(5, min_samples_minority - 1) if min_samples_minority > 1 else 0

    if k_neighbors_smote > 0:
        smote = SMOTE(random_state=42, k_neighbors=k_neighbors_smote)
        X_balanced, y_balanced = smote.fit_resample(X_train, y_train)
        # Contar clases despu√©s del balanceo
        counter_after = Counter(y_balanced)
        print("\nDistribuci√≥n despu√©s del balanceo:")
        for clase, count in counter_after.items():
            print(f"  {label_encoder.inverse_transform([clase])[0]}: {count}")
    else:
        print("\nSkipping SMOTE: Not enough samples in minority class for oversampling.")
        X_balanced, y_balanced = X_train, y_train


    return X_balanced, y_balanced

X_train_balanced, y_train_balanced = aplicar_balanceo(X_train, y_train)

# Optimizaci√≥n de hiperpar√°metros con Optuna
def optimize_classifier(X_train, y_train, X_test, y_test, n_trials=50):
    """Optimiza hiperpar√°metros usando Optuna"""

    def objective(trial):
        # Sugerir tipo de clasificador
        classifier_name = trial.suggest_categorical('classifier', ['logistic', 'svm', 'rf', 'gb'])

        if classifier_name == 'logistic':
            C = trial.suggest_float('C', 1e-3, 1e3, log=True)
            max_iter = trial.suggest_int('max_iter', 500, 2000)
            solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs'])
            classifier = LogisticRegression(C=C, max_iter=max_iter, solver=solver, random_state=42)

        elif classifier_name == 'svm':
            C = trial.suggest_float('svm_C', 1e-3, 1e3, log=True)
            gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])
            kernel = trial.suggest_categorical('kernel', ['rbf', 'linear'])
            classifier = SVC(C=C, gamma=gamma, kernel=kernel, probability=True, random_state=42)

        elif classifier_name == 'rf':
            n_estimators = trial.suggest_int('n_estimators', 50, 300)
            max_depth = trial.suggest_int('max_depth', 5, 20)
            min_samples_split = trial.suggest_int('min_samples_split', 2, 10)
            classifier = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                random_state=42
            )

        else:  # gradient boosting
            n_estimators = trial.suggest_int('gb_n_estimators', 50, 200)
            learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)
            max_depth = trial.suggest_int('gb_max_depth', 3, 10)
            classifier = GradientBoostingClassifier(
                n_estimators=n_estimators,
                learning_rate=learning_rate,
                max_depth=max_depth,
                random_state=42
            )

        # Validaci√≥n cruzada
        # Ensure there's more than one class for scoring
        if len(np.unique(y_train)) > 1:
            cv_scores = cross_val_score(classifier, X_train, y_train, cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42), scoring='f1_weighted')
            return cv_scores.mean()
        else:
             # If only one class, return a low value so Optuna doesn't favor this
            return -1.0


    print("\n" + "="*50)
    print("OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS")
    print("="*50)

    study = optuna.create_study(direction='maximize')
    # Check if there's more than one class before optimizing
    if len(np.unique(y_train)) > 1:
        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

        print(f"Mejor F1 score en validaci√≥n cruzada: {study.best_value:.4f}")
        print(f"Mejores par√°metros: {study.best_params}")

        return study.best_params
    else:
        print("Skipping Optuna: Only one class present after balanceo.")
        # Return default parameters or handle accordingly
        return {'classifier': 'logistic', 'C': 1.0, 'max_iter': 1000, 'solver': 'lbfgs'} # Example defaults

# Ejecutar optimizaci√≥n (reducir n_trials si es muy lento)
best_params = optimize_classifier(X_train_balanced, y_train_balanced, X_test, y_test, n_trials=10) # Reduced trials for faster execution

# Entrenar el mejor modelo
def train_best_model(best_params, X_train, y_train):
    """Entrena el modelo con los mejores par√°metros"""
    classifier_name = best_params['classifier']

    if classifier_name == 'logistic':
        classifier = LogisticRegression(
            C=best_params.get('C', 1.0), # Use .get for robustness
            max_iter=best_params.get('max_iter', 1000),
            solver=best_params.get('solver', 'lbfgs'),
            random_state=42
        )
    elif classifier_name == 'svm':
        classifier = SVC(
            C=best_params.get('svm_C', 1.0),
            gamma=best_params.get('gamma', 'scale'),
            kernel=best_params.get('kernel', 'rbf'),
            probability=True,
            random_state=42
        )
    elif classifier_name == 'rf':
        classifier = RandomForestClassifier(
            n_estimators=best_params.get('n_estimators', 100),
            max_depth=best_params.get('max_depth', 10),
            min_samples_split=best_params.get('min_samples_split', 2),
            random_state=42
        )
    else:  # gradient boosting
        classifier = GradientBoostingClassifier(
            n_estimators=best_params.get('gb_n_estimators', 100),
            learning_rate=best_params.get('learning_rate', 0.1),
            max_depth=best_params.get('gb_max_depth', 3),
            random_state=42
        )

    # Ensure training happens only if there's data
    if X_train.shape[0] > 0:
         classifier.fit(X_train, y_train)
    else:
        print("Skipping model training: Training data is empty.")
        classifier = None # Or handle appropriately

    return classifier

best_classifier = train_best_model(best_params, X_train_balanced, y_train_balanced)

# Evaluation section should only run if best_classifier is not None
if best_classifier is not None:
    # Evaluaci√≥n completa
    print("\n" + "="*50)
    print("EVALUACI√ìN DEL MODELO OPTIMIZADO")
    print("="*50)

    # Ensure y_test is not empty before predicting
    if X_test.shape[0] > 0:
        y_pred = best_classifier.predict(X_test)
        y_prob = best_classifier.predict_proba(X_test)

        # M√©tricas detalladas
        accuracy = accuracy_score(y_test, y_pred)
        f1_weighted = f1_score(y_test, y_pred, average='weighted')
        f1_macro = f1_score(y_test, y_pred, average='macro')
        recall_weighted = recall_score(y_test, y_pred, average='weighted')
        recall_macro = recall_score(y_test, y_pred, average='macro')

        # ROC-AUC requires probabilities and multiple classes
        try:
            if len(np.unique(y_test)) > 1 and y_prob.shape[1] > 1:
                roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')
            else:
                roc_auc = np.nan # Not applicable for single class or binary probas in multi-class scenario
        except Exception as e:
            print(f"Could not calculate ROC-AUC. Error: {e}")
            roc_auc = np.nan

        print(f"Modelo utilizado: {selected_model}")
        print(f"Clasificador: {best_params['classifier']}")
        print(f"\nM√âTRICAS:")
        print(f"Accuracy: {accuracy:.4f}")
        print(f"F1 Score (Weighted): {f1_weighted:.4f}")
        print(f"F1 Score (Macro): {f1_macro:.4f}")
        if not np.isnan(roc_auc):
            print(f"ROC-AUC: {roc_auc:.4f}")

        # Reporte de clasificaci√≥n detallado
        print(f"\nREPORTE DE CLASIFICACI√ìN DETALLADO:")
        print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

        # Matriz de confusi√≥n mejorada
        conf_matrix = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(12, 10))
        sns.heatmap(
            conf_matrix,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_,
            cbar_kws={'label': 'N√∫mero de muestras'}
        )
        plt.xlabel('Etiqueta Predicha', fontsize=12)
        plt.ylabel('Etiqueta Verdadera', fontsize=12)
        plt.title(f'Matriz de Confusi√≥n Optimizada\nModelo: {selected_model} | Clasificador: {best_params["classifier"]}', fontsize=14)
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.show()

        # An√°lisis de errores por clase
        print(f"\nAN√ÅLISIS DE ERRORES POR CLASE:")
        for i, clase in enumerate(label_encoder.classes_):
            mask = y_test == i
            if mask.sum() > 0:
                accuracy_clase = accuracy_score(y_test[mask], y_pred[mask])
                print(f"{clase}: {accuracy_clase:.3f} ({mask.sum()} muestras)")
    else:
        print("Skipping evaluation: Test data is empty.")

# Funci√≥n de predicci√≥n mejorada - versi√≥n corregida
def predict_emotion_advanced(text, tokenizer, model, classifier, label_encoder, scaler, device):
    """Funci√≥n de predicci√≥n mejorada con el modelo optimizado - versi√≥n corregida"""
    if classifier is None:
         return {'emocion': 'Modelo no entrenado', 'confianza': 0.0, 'probabilidades': {}}

    if not text or text.strip() == '':
        return {'emocion': 'Texto vac√≠o', 'confianza': 0.0, 'probabilidades': {}}

    # Generar embedding usando la same function based on use_advanced flag
    # Note: This function now calls the simple one to avoid the advanced pooling complexity if needed.
    # If use_advanced is True, it would ideally call the advanced one, but we simplified here for robustness.
    text_embedding = generate_embeddings_simple([text], tokenizer, model, device)
    text_embedding_scaled = scaler.transform(text_embedding)

    # Predecir
    # Ensure classifier can handle predict_proba (SVC needs probability=True)
    if hasattr(classifier, 'predict_proba'):
         predicted_proba = classifier.predict_proba(text_embedding_scaled)[0]
         predicted_label = classifier.predict(text_embedding_scaled)[0]
         confidence = predicted_proba.max()

         # Probabilities by class
         probabilidades = {}
         for i, emocion in enumerate(label_encoder.classes_):
             probabilidades[emocion] = predicted_proba[i]
    else:
        # Fallback if predict_proba is not available (e.g., certain SVC configs)
        predicted_label = classifier.predict(text_embedding_scaled)[0]
        confidence = 1.0 # Assume high confidence if no proba
        probabilidades = {label_encoder.inverse_transform([predicted_label])[0]: 1.0} # Only the predicted class

    # Decode
    predicted_emotion = label_encoder.inverse_transform([predicted_label])[0]


    return {
        'emocion': predicted_emotion,
        'confianza': confidence,
        'probabilidades': probabilidades
    }


# Ejemplos de predicci√≥n con el modelo optimizado
print("\n" + "="*50)
print("EJEMPLOS CON MODELO OPTIMIZADO")
print("="*50)

textos_ejemplo = [
    "¬°Estoy s√∫per feliz! Hoy consegu√≠ el trabajo de mis sue√±os",
    "Me siento muy triste y melanc√≥lico, como si nada tuviera sentido",
    "¬°No puedo creer lo que acaba de pasar! ¬°Qu√© sorpresa incre√≠ble!",
    "Estoy furioso, esto es completamente inaceptable e injusto",
    "Tengo p√°nico, no s√© qu√© va a pasar y estoy muy nervioso",
    "Esta situaci√≥n me da mucho asco, es repugnante"
]

# Only run examples if the model was successfully trained
if best_classifier is not None:
    for texto in textos_ejemplo:
        try:
            # Always use the predict_emotion_advanced function, which internally calls the simple embedding one
            # or handles the advanced one based on the success/failure during training data processing.
            # Given the RuntimeError on advanced, we should ensure the simple embedding is used here for prediction.
            # The predict_emotion_advanced function was modified to call generate_embeddings_simple
            resultado = predict_emotion_advanced(texto, tokenizer, model, best_classifier, label_encoder, scaler, device)

            print(f"\nTexto: '{texto}'")
            print(f"Emoci√≥n: {resultado['emocion']} (confianza: {resultado['confianza']:.3f})")

            # Top 2 probabilities
            prob_sorted = sorted(resultado['probabilidades'].items(), key=lambda x: x[1], reverse=True)
            print("Probabilidades:")
            for emocion, prob in prob_sorted[:2]:
                print(f"  {emocion}: {prob:.3f}")
        except Exception as e:
            print(f"Error prediciendo '{texto}': {e}")
else:
    print("Skipping prediction examples: Model training failed.")


print("\n" + "="*60)
print("OPTIMIZACI√ìN COMPLETADA")
print("="*60)


# --- Code from the second cell starts here ---

# Funci√≥n optimizada para SVM con m√∫ltiples kernels
def optimize_svm_classifier(X_train, y_train, X_test, y_test, n_trials=100):
    """Optimizaci√≥n espec√≠fica para SVM con enfoque en diferentes kernels"""

    def objective(trial):
        # Kernel espec√≠fico con par√°metros optimizados
        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])

        if kernel == 'linear':
            C = trial.suggest_float('C', 1e-4, 1e3, log=True)
            classifier = SVC(kernel='linear', C=C, probability=True, random_state=42)

        elif kernel == 'poly':
            C = trial.suggest_float('C', 1e-4, 1e3, log=True)
            degree = trial.suggest_int('degree', 2, 5)  # Grados 2-5 son m√°s pr√°cticos
            gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])
            coef0 = trial.suggest_float('coef0', 0.0, 1.0)
            classifier = SVC(kernel='poly', C=C, degree=degree, gamma=gamma,
                           coef0=coef0, probability=True, random_state=42)

        elif kernel == 'rbf':
            C = trial.suggest_float('C', 1e-4, 1e3, log=True)
            gamma = trial.suggest_float('gamma', 1e-6, 1e0, log=True)
            classifier = SVC(kernel='rbf', C=C, gamma=gamma, probability=True, random_state=42)

        else:  # sigmoid
            C = trial.suggest_float('C', 1e-4, 1e3, log=True)
            gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])
            coef0 = trial.suggest_float('coef0', -1.0, 1.0)
            classifier = SVC(kernel='sigmoid', C=C, gamma=gamma,
                           coef0=coef0, probability=True, random_state=42)

        # Validaci√≥n cruzada m√°s robusta
        if len(np.unique(y_train)) > 1:
            cv_scores = cross_val_score(
                classifier, X_train, y_train,
                cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
                scoring='f1_weighted',
                n_jobs=-1  # Paralelizaci√≥n
            )
            return cv_scores.mean()
        else:
            return -1.0

    print("\n" + "="*60)
    print("OPTIMIZACI√ìN ESPEC√çFICA PARA SVM")
    print("="*60)

    # Configuraci√≥n m√°s agresiva de Optuna
    study = optuna.create_study(
        direction='maximize',
        sampler=optuna.samplers.TPESampler(seed=42),
        pruner=optuna.pruners.MedianPruner()
    )

    if len(np.unique(y_train)) > 1:
        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

        print(f"Mejor F1 score: {study.best_value:.4f}")
        print(f"Mejores par√°metros SVM: {study.best_params}")

        return study.best_params
    else:
        print("Solo una clase presente, usando par√°metros por defecto")
        return {'kernel': 'rbf', 'C': 1.0, 'gamma': 'scale'}

# Comparaci√≥n exhaustiva de diferentes enfoques
def compare_multiple_models(X_train, y_train, X_test, y_test):
    """Compara m√∫ltiples modelos y configuraciones"""
"""Proyecto_Transformers_Optimizado.ipynb

An√°lisis de emociones optimizado con m√∫ltiples mejoras
"""

!pip install transformers scikit-learn torch imbalanced-learn optuna

import pandas as pd
import numpy as np
from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification
import torch
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.preprocessing import label_binarize
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import optuna
from collections import Counter
import time # Added the missing import for time
warnings.filterwarnings('ignore')

# Load the dataset
df = pd.read_csv('Nuevo_Dataset_Patrones_Emocionales.csv')

def emocion_para_columna(col):
    """Asocia cada pregunta con su emoci√≥n correspondiente"""
    pregunta_numero = int(col.split('.')[0])
    if pregunta_numero in [1, 2]:
        return 'Felicidad'
    elif pregunta_numero in [3, 4]:
        return 'Tristeza'
    elif pregunta_numero in [5, 6]:
        return 'Disgusto'
    elif pregunta_numero in [7, 8]:
        return 'Ira'
    elif pregunta_numero in [9, 10]:
        return 'Miedo'
    elif pregunta_numero in [11, 12]:
        return 'Sorpresa'
    return None

# An√°lisis exploratorio de datos mejorado
def analizar_datos(df):
    """Realiza un an√°lisis detallado del dataset"""
    print("="*60)
    print("AN√ÅLISIS EXPLORATORIO DE DATOS")
    print("="*60)

    preguntas_reales = [col for col in df.columns if col.strip()[0].isdigit()]
    print(f"N√∫mero de preguntas encontradas: {len(preguntas_reales)}")
    print(f"Preguntas: {preguntas_reales[:5]}...")  # Mostrar primeras 5

    # Crear dataset de respuestas
    data_respuestas = pd.DataFrame()
    for pregunta in preguntas_reales:
        emocion = emocion_para_columna(pregunta)
        temp_df = pd.DataFrame({
            'Pregunta': [pregunta] * len(df),
            'Respuesta': df[pregunta],
            'Emocion': [emocion] * len(df)
        })
        data_respuestas = pd.concat([data_respuestas, temp_df], ignore_index=True)

    # Limpieza inicial
    print(f"\nAntes de limpieza: {len(data_respuestas)} respuestas")
    data_respuestas = data_respuestas.dropna(subset=['Respuesta'])
    data_respuestas = data_respuestas[data_respuestas['Respuesta'].str.strip() != '']
    print(f"Despu√©s de limpieza: {len(data_respuestas)} respuestas")

    # An√°lisis de distribuci√≥n
    print(f"\nDistribuci√≥n de emociones:")
    distribucion = data_respuestas['Emocion'].value_counts()
    print(distribucion)

    # Calcular ratio de desbalance
    max_count = distribucion.max()
    min_count = distribucion.min()
    ratio_desbalance = max_count / min_count
    print(f"\nRatio de desbalance: {ratio_desbalance:.2f}")

    if ratio_desbalance > 2:
        print("‚ö†Ô∏è  Dataset desbalanceado detectado - se aplicar√° balanceo")

    # An√°lisis de longitud de respuestas
    data_respuestas['longitud'] = data_respuestas['Respuesta'].str.len()
    print(f"\nEstad√≠sticas de longitud de respuestas:")
    print(f"Media: {data_respuestas['longitud'].mean():.1f} caracteres")
    print(f"Mediana: {data_respuestas['longitud'].median():.1f} caracteres")
    print(f"Min: {data_respuestas['longitud'].min()} - Max: {data_respuestas['longitud'].max()}")

    return data_respuestas

# An√°lisis del dataset
data_respuestas_con_emociones = analizar_datos(df)

# Funci√≥n mejorada para cargar modelos
def load_model_safely(model_names):
    """Intenta cargar modelos con mejor manejo de errores"""
    for i, model_name in enumerate(model_names, 1):
        try:
            print(f"Intentando cargar modelo {i}: {model_name}")
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModel.from_pretrained(model_name)
            print(f"‚úÖ Modelo cargado exitosamente: {model_name}")
            return tokenizer, model, model_name
        except Exception as e:
            print(f"‚ùå Error con {model_name}: {str(e)[:100]}...")
            continue

    print("‚ùå No se pudo cargar ning√∫n modelo")
    return None, None, None

# Lista ampliada de modelos
models_to_try = [
    "pysentimiento/robertuito-base-cased",
    "dccuchile/bert-base-spanish-wwm-cased",
    "cardiffnlp/twitter-roberta-base-emotion-multilingual",
    "xlm-roberta-base",
    "distilbert-base-multilingual-cased"
]

tokenizer, model, selected_model = load_model_safely(models_to_try)

if tokenizer is None:
    print("No se pudo cargar ning√∫n modelo. Verificar conexi√≥n a internet.")
    exit()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando device: {device}")
model.to(device)

# Function to generate embeddings (Simple version as backup)
def generate_embeddings_simple(texts, tokenizer, model, device, batch_size=16):
    """Versi√≥n simplificada que solo usa mean pooling"""
    embeddings = []
    model.eval()

    with torch.no_grad():
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            encoded_input = tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                return_tensors='pt',
                max_length=128  # Reducido para mayor compatibilidad
            )

            input_ids = encoded_input['input_ids'].to(device)
            attention_mask = encoded_input['attention_mask'].to(device)

            outputs = model(input_ids, attention_mask=attention_mask)
            last_hidden_states = outputs.last_hidden_state

            # Solo mean pooling para evitar problems de dimensiones
            attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_states.size()).float()
            masked_embeddings = last_hidden_states * attention_mask_expanded
            sum_embeddings = torch.sum(masked_embeddings, 1)
            sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)
            mean_pooled = sum_embeddings / sum_mask

            embeddings.extend(mean_pooled.cpu().numpy())

    return np.array(embeddings)

def generate_embeddings_advanced(texts, tokenizer, model, device, batch_size=16, max_length=256):
    """Generaci√≥n de embeddings con m√∫ltiples estrategias de pooling - versi√≥n corregida"""
    embeddings = []
    model.eval()

    with torch.no_grad():
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            encoded_input = tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                return_tensors='pt',
                max_length=max_length
            )

            input_ids = encoded_input['input_ids'].to(device)
            attention_mask = encoded_input['attention_mask'].to(device)
            # Note: We are NOT explicitly providing token_type_ids here.
            # The model might generate them internally, and this is where the error potentially lies.
            # Keeping the advanced logic as is for now, but moving the simple function definition.

            outputs = model(input_ids, attention_mask=attention_mask)
            last_hidden_states = outputs.last_hidden_state

            # Obtener dimensiones correctas
            batch_size_actual = last_hidden_states.size(0)
            seq_length = last_hidden_states.size(1)
            hidden_size = last_hidden_states.size(2)

            # Expandir m√°scara de atenci√≥n correctamente
            attention_mask_expanded = attention_mask.unsqueeze(-1).expand(batch_size_actual, seq_length, hidden_size).float()

            # 1. Mean pooling (promedio ponderado)
            masked_embeddings = last_hidden_states * attention_mask_expanded
            sum_embeddings = torch.sum(masked_embeddings, 1)
            sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)
            mean_pooled = sum_embeddings / sum_mask

            # 2. Max pooling
            masked_embeddings_max = last_hidden_states.clone()
            masked_embeddings_max[attention_mask_expanded == 0] = -1e9
            max_pooled = torch.max(masked_embeddings_max, 1)[0]

            # 3. CLS token (primer token)
            cls_embeddings = last_hidden_states[:, 0, :]

            # Concatenar diferentes tipos de pooling para mayor riqueza
            # Verify dimensions before concatenating - this was helpful for debugging
            # print(f"Debug - Mean pooled shape: {mean_pooled.shape}")
            # print(f"Debug - Max pooled shape: {max_pooled.shape}")
            # print(f"Debug - CLS embeddings shape: {cls_embeddings.shape}")

            combined_embeddings = torch.cat([mean_pooled, max_pooled, cls_embeddings], dim=1)

            embeddings.extend(combined_embeddings.cpu().numpy())

    return np.array(embeddings)


print("Generando embeddings avanzados...")
respuestas_texto = data_respuestas_con_emociones['Respuesta'].fillna('').astype(str).tolist()

# Primero intentamos con embeddings avanzados, si falla usamos simples
try:
    print("Intentando con embeddings avanzados (triple pooling)...")
    # Probar con a batch first to see if it works
    text_embeddings = generate_embeddings_advanced(respuestas_texto[:16], tokenizer, model, device)
    print("‚úÖ Embeddings avanzados funcionan correctamente con un batch")
    # If the test batch works, process the full data
    text_embeddings = generate_embeddings_advanced(respuestas_texto, tokenizer, model, device)
    use_advanced = True
except Exception as e:
    print(f"‚ùå Error con embeddings avanzados: {e}")
    print("üîÑ Cambiando a embeddings simples...")
    # The generate_embeddings_simple function is now defined above
    text_embeddings = generate_embeddings_simple(respuestas_texto, tokenizer, model, device)
    use_advanced = False

print(f"Embeddings generados: {text_embeddings.shape}")
print(f"Tipo de embedding usado: {'Avanzado (triple pooling)' if use_advanced else 'Simple (mean pooling)'}")

# Preparaci√≥n de datos mejorada
label_encoder = LabelEncoder()
emociones_texto = data_respuestas_con_emociones['Emocion'].fillna('').astype(str).tolist()
encoded_labels = label_encoder.fit_transform(emociones_texto)

# Normalizaci√≥n de features
scaler = StandardScaler()
text_embeddings_scaled = scaler.fit_transform(text_embeddings)

# Divisi√≥n estratificada
X_train, X_test, y_train, y_test = train_test_split(
    text_embeddings_scaled,
    encoded_labels,
    test_size=0.2,
    random_state=42,
    stratify=encoded_labels
)

print(f"Conjunto de entrenamiento: {X_train.shape}")
print(f"Conjunto de prueba: {X_test.shape}")

# An√°lisis de desbalance y aplicaci√≥n de SMOTE
def aplicar_balanceo(X_train, y_train):
    """Aplica t√©cnicas de balanceo de clases"""
    print("\n" + "="*50)
    print("BALANCEO DE CLASES")
    print("="*50)

    # Contar clases antes del balanceo
    counter_before = Counter(y_train)
    print("Distribuci√≥n antes del balanceo:")
    for clase, count in counter_before.items():
        print(f"  {label_encoder.inverse_transform([clase])[0]}: {count}")

    # Aplicar SMOTE para sobremuestreo
    # Ensure k_neighbors is less than or equal to the number of samples in the minority class minus 1
    min_samples_minority = min(counter_before.values())
    k_neighbors_smote = min(5, min_samples_minority - 1) if min_samples_minority > 1 else 0

    if k_neighbors_smote > 0:
        smote = SMOTE(random_state=42, k_neighbors=k_neighbors_smote)
        X_balanced, y_balanced = smote.fit_resample(X_train, y_train)
        # Contar clases despu√©s del balanceo
        counter_after = Counter(y_balanced)
        print("\nDistribuci√≥n despu√©s del balanceo:")
        for clase, count in counter_after.items():
            print(f"  {label_encoder.inverse_transform([clase])[0]}: {count}")
    else:
        print("\nSkipping SMOTE: Not enough samples in minority class for oversampling.")
        X_balanced, y_balanced = X_train, y_train


    return X_balanced, y_balanced

X_train_balanced, y_train_balanced = aplicar_balanceo(X_train, y_train)

# Optimizaci√≥n de hiperpar√°metros con Optuna
def optimize_classifier(X_train, y_train, X_test, y_test, n_trials=50):
    """Optimiza hiperpar√°metros usando Optuna"""

    def objective(trial):
        # Sugerir tipo de clasificador
        classifier_name = trial.suggest_categorical('classifier', ['logistic', 'svm', 'rf', 'gb'])

        if classifier_name == 'logistic':
            C = trial.suggest_float('C', 1e-3, 1e3, log=True)
            max_iter = trial.suggest_int('max_iter', 500, 2000)
            solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs'])
            classifier = LogisticRegression(C=C, max_iter=max_iter, solver=solver, random_state=42)

        elif classifier_name == 'svm':
            C = trial.suggest_float('svm_C', 1e-3, 1e3, log=True)
            gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])
            kernel = trial.suggest_categorical('kernel', ['rbf', 'linear'])
            classifier = SVC(C=C, gamma=gamma, kernel=kernel, probability=True, random_state=42)

        elif classifier_name == 'rf':
            n_estimators = trial.suggest_int('n_estimators', 50, 300)
            max_depth = trial.suggest_int('max_depth', 5, 20)
            min_samples_split = trial.suggest_int('min_samples_split', 2, 10)
            classifier = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                random_state=42
            )

        else:  # gradient boosting
            n_estimators = trial.suggest_int('gb_n_estimators', 50, 200)
            learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)
            max_depth = trial.suggest_int('gb_max_depth', 3, 10)
            classifier = GradientBoostingClassifier(
                n_estimators=n_estimators,
                learning_rate=learning_rate,
                max_depth=max_depth,
                random_state=42
            )

        # Validaci√≥n cruzada
        # Ensure there's more than one class for scoring
        if len(np.unique(y_train)) > 1:
            cv_scores = cross_val_score(classifier, X_train, y_train, cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42), scoring='f1_weighted')
            return cv_scores.mean()
        else:
             # If only one class, return a low value so Optuna doesn't favor this
            return -1.0


    print("\n" + "="*50)
    print("OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS")
    print("="*50)

    study = optuna.create_study(direction='maximize')
    # Check if there's more than one class before optimizing
    if len(np.unique(y_train)) > 1:
        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

        print(f"Mejor F1 score en validaci√≥n cruzada: {study.best_value:.4f}")
        print(f"Mejores par√°metros: {study.best_params}")

        return study.best_params
    else:
        print("Skipping Optuna: Only one class present after balanceo.")
        # Return default parameters or handle accordingly
        return {'classifier': 'logistic', 'C': 1.0, 'max_iter': 1000, 'solver': 'lbfgs'} # Example defaults

# Ejecutar optimizaci√≥n (reducir n_trials si es muy lento)
best_params = optimize_classifier(X_train_balanced, y_train_balanced, X_test, y_test, n_trials=10) # Reduced trials for faster execution

# Entrenar el mejor modelo
def train_best_model(best_params, X_train, y_train):
    """Entrena el modelo con los mejores par√°metros"""
    classifier_name = best_params['classifier']

    if classifier_name == 'logistic':
        classifier = LogisticRegression(
            C=best_params.get('C', 1.0), # Use .get for robustness
            max_iter=best_params.get('max_iter', 1000),
            solver=best_params.get('solver', 'lbfgs'),
            random_state=42
        )
    elif classifier_name == 'svm':
        classifier = SVC(
            C=best_params.get('svm_C', 1.0),
            gamma=best_params.get('gamma', 'scale'),
            kernel=best_params.get('kernel', 'rbf'),
            probability=True,
            random_state=42
        )
    elif classifier_name == 'rf':
        classifier = RandomForestClassifier(
            n_estimators=best_params.get('n_estimators', 100),
            max_depth=best_params.get('max_depth', 10),
            min_samples_split=best_params.get('min_samples_split', 2),
            random_state=42
        )
    else:  # gradient boosting
        classifier = GradientBoostingClassifier(
            n_estimators=best_params.get('gb_n_estimators', 100),
            learning_rate=best_params.get('learning_rate', 0.1),
            max_depth=best_params.get('gb_max_depth', 3),
            random_state=42
        )

    # Ensure training happens only if there's data
    if X_train.shape[0] > 0:
         classifier.fit(X_train, y_train)
    else:
        print("Skipping model training: Training data is empty.")
        classifier = None # Or handle appropriately

    return classifier

best_classifier = train_best_model(best_params, X_train_balanced, y_train_balanced)

# Evaluation section should only run if best_classifier is not None
if best_classifier is not None:
    # Evaluaci√≥n completa
    print("\n" + "="*50)
    print("EVALUACI√ìN DEL MODELO OPTIMIZADO")
    print("="*50)

    # Ensure y_test is not empty before predicting
    if X_test.shape[0] > 0:
        y_pred = best_classifier.predict(X_test)
        y_prob = best_classifier.predict_proba(X_test)

        # M√©tricas detalladas
        accuracy = accuracy_score(y_test, y_pred)
        f1_weighted = f1_score(y_test, y_pred, average='weighted')
        f1_macro = f1_score(y_test, y_pred, average='macro')
        recall_weighted = recall_score(y_test, y_pred, average='weighted')
        recall_macro = recall_score(y_test, y_pred, average='macro')

        # ROC-AUC requires probabilities and multiple classes
        try:
            if len(np.unique(y_test)) > 1 and y_prob.shape[1] > 1:
                roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')
            else:
                roc_auc = np.nan # Not applicable for single class or binary probas in multi-class scenario
        except Exception as e:
            print(f"Could not calculate ROC-AUC. Error: {e}")
            roc_auc = np.nan

        print(f"Modelo utilizado: {selected_model}")
        print(f"Clasificador: {best_params['classifier']}")
        print(f"\nM√âTRICAS:")
        print(f"Accuracy: {accuracy:.4f}")
        print(f"F1 Score (Weighted): {f1_weighted:.4f}")
        print(f"F1 Score (Macro): {f1_macro:.4f}")
        if not np.isnan(roc_auc):
            print(f"ROC-AUC: {roc_auc:.4f}")

        # Reporte de clasificaci√≥n detallado
        print(f"\nREPORTE DE CLASIFICACI√ìN DETALLADO:")
        print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

        # Matriz de confusi√≥n mejorada
        conf_matrix = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(12, 10))
        sns.heatmap(
            conf_matrix,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_,
            cbar_kws={'label': 'N√∫mero de muestras'}
        )
        plt.xlabel('Etiqueta Predicha', fontsize=12)
        plt.ylabel('Etiqueta Verdadera', fontsize=12)
        plt.title(f'Matriz de Confusi√≥n Optimizada\nModelo: {selected_model} | Clasificador: {best_params["classifier"]}', fontsize=14)
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.show()

        # An√°lisis de errores por clase
        print(f"\nAN√ÅLISIS DE ERRORES POR CLASE:")
        for i, clase in enumerate(label_encoder.classes_):
            mask = y_test == i
            if mask.sum() > 0:
                accuracy_clase = accuracy_score(y_test[mask], y_pred[mask])
                print(f"{clase}: {accuracy_clase:.3f} ({mask.sum()} muestras)")
    else:
        print("Skipping evaluation: Test data is empty.")

# Funci√≥n de predicci√≥n mejorada - versi√≥n corregida
def predict_emotion_advanced(text, tokenizer, model, classifier, label_encoder, scaler, device):
    """Funci√≥n de predicci√≥n mejorada con el modelo optimizado - versi√≥n corregida"""
    if classifier is None:
         return {'emocion': 'Modelo no entrenado', 'confianza': 0.0, 'probabilidades': {}}

    if not text or text.strip() == '':
        return {'emocion': 'Texto vac√≠o', 'confianza': 0.0, 'probabilidades': {}}

    # Generar embedding usando la same function based on use_advanced flag
    # Note: This function now calls the simple one to avoid the advanced pooling complexity if needed.
    # If use_advanced is True, it would ideally call the advanced one, but we simplified here for robustness.
    text_embedding = generate_embeddings_simple([text], tokenizer, model, device)
    text_embedding_scaled = scaler.transform(text_embedding)

    # Predecir
    # Ensure classifier can handle predict_proba (SVC needs probability=True)
    if hasattr(classifier, 'predict_proba'):
         predicted_proba = classifier.predict_proba(text_embedding_scaled)[0]
         predicted_label = classifier.predict(text_embedding_scaled)[0]
         confidence = predicted_proba.max()

         # Probabilities by class
         probabilidades = {}
         for i, emocion in enumerate(label_encoder.classes_):
             probabilidades[emocion] = predicted_proba[i]
    else:
        # Fallback if predict_proba is not available (e.g., certain SVC configs)
        predicted_label = classifier.predict(text_embedding_scaled)[0]
        confidence = 1.0 # Assume high confidence if no proba
        probabilidades = {label_encoder.inverse_transform([predicted_label])[0]: 1.0} # Only the predicted class

    # Decode
    predicted_emotion = label_encoder.inverse_transform([predicted_label])[0]


    return {
        'emocion': predicted_emotion,
        'confianza': confidence,
        'probabilidades': probabilidades
    }


# Ejemplos de predicci√≥n con el modelo optimizado
print("\n" + "="*50)
print("EJEMPLOS CON MODELO OPTIMIZADO")
print("="*50)

textos_ejemplo = [
    "¬°Estoy s√∫per feliz! Hoy consegu√≠ el trabajo de mis sue√±os",
    "Me siento muy triste y melanc√≥lico, como si nada tuviera sentido",
    "¬°No puedo creer lo que acaba de pasar! ¬°Qu√© sorpresa incre√≠ble!",
    "Estoy furioso, esto es completamente inaceptable e injusto",
    "Tengo p√°nico, no s√© qu√© va a pasar y estoy muy nervioso",
    "Esta situaci√≥n me da mucho asco, es repugnante"
]

# Only run examples if the model was successfully trained
if best_classifier is not None:
    for texto in textos_ejemplo:
        try:
            # Always use the predict_emotion_advanced function, which internally calls the simple embedding one
            # or handles the advanced one based on the success/failure during training data processing.
            # Given the RuntimeError on advanced, we should ensure the simple embedding is used here for prediction.
            # The predict_emotion_advanced function was modified to call generate_embeddings_simple
            resultado = predict_emotion_advanced(texto, tokenizer, model, best_classifier, label_encoder, scaler, device)

            print(f"\nTexto: '{texto}'")
            print(f"Emoci√≥n: {resultado['emocion']} (confianza: {resultado['confianza']:.3f})")

            # Top 2 probabilities
            prob_sorted = sorted(resultado['probabilidades'].items(), key=lambda x: x[1], reverse=True)
            print("Probabilidades:")
            for emocion, prob in prob_sorted[:2]:
                print(f"  {emocion}: {prob:.3f}")
        except Exception as e:
            print(f"Error prediciendo '{texto}': {e}")
else:
    print("Skipping prediction examples: Model training failed.")


print("\n" + "="*60)
print("OPTIMIZACI√ìN COMPLETADA")
print("="*60)


# --- Code from the second cell starts here ---

# Funci√≥n optimizada para SVM con m√∫ltiples kernels
def optimize_svm_classifier(X_train, y_train, X_test, y_test, n_trials=100):
    """Optimizaci√≥n espec√≠fica para SVM con enfoque en diferentes kernels"""

    def objective(trial):
        # Kernel espec√≠fico con par√°metros optimizados
        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])

        if kernel == 'linear':
            C = trial.suggest_float('C', 1e-4, 1e3, log=True)
            classifier = SVC(kernel='linear', C=C, probability=True, random_state=42)

        elif kernel == 'poly':
            C = trial.suggest_float('C', 1e-4, 1e3, log=True)
            degree = trial.suggest_int('degree', 2, 5)  # Grados 2-5 son m√°s pr√°cticos
            gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])
            coef0 = trial.suggest_float('coef0', 0.0, 1.0)
            classifier = SVC(kernel='poly', C=C, degree=degree, gamma=gamma,
                           coef0=coef0, probability=True, random_state=42)

        elif kernel == 'rbf':
            C = trial.suggest_float('C', 1e-4, 1e3, log=True)
            gamma = trial.suggest_float('gamma', 1e-6, 1e0, log=True)
            classifier = SVC(kernel='rbf', C=C, gamma=gamma, probability=True, random_state=42)

        else:  # sigmoid
            C = trial.suggest_float('C', 1e-4, 1e3, log=True)
            gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])
            coef0 = trial.suggest_float('coef0', -1.0, 1.0)
            classifier = SVC(kernel='sigmoid', C=C, gamma=gamma,
                           coef0=coef0, probability=True, random_state=42)

        # Validaci√≥n cruzada m√°s robusta
        if len(np.unique(y_train)) > 1:
            cv_scores = cross_val_score(
                classifier, X_train, y_train,
                cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
                scoring='f1_weighted',
                n_jobs=-1  # Paralelizaci√≥n
            )
            return cv_scores.mean()
        else:
            return -1.0

    print("\n" + "="*60)
    print("OPTIMIZACI√ìN ESPEC√çFICA PARA SVM")
    print("="*60)

    # Configuraci√≥n m√°s agresiva de Optuna
    study = optuna.create_study(
        direction='maximize',
        sampler=optuna.samplers.TPESampler(seed=42),
        pruner=optuna.pruners.MedianPruner()
    )

    if len(np.unique(y_train)) > 1:
        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

        print(f"Mejor F1 score: {study.best_value:.4f}")
        print(f"Mejores par√°metros SVM: {study.best_params}")

        return study.best_params
    else:
        print("Solo una clase presente, usando par√°metros por defecto")
        return {'kernel': 'rbf', 'C': 1.0, 'gamma': 'scale'}

# Comparaci√≥n exhaustiva de diferentes enfoques
def compare_multiple_models(X_train, y_train, X_test, y_test):
    """Compara m√∫ltiples modelos y configuraciones"""

    models_to_test = {
        'SVM_Linear': SVC(kernel='linear', probability=True, random_state=42),
        'SVM_RBF': SVC(kernel='rbf', probability=True, random_state=42),
        'Logistic Regression': LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
    }

    results = {}

    print("\n" + "="*60)
    print("COMPARACI√ìN DE M√öLTIPLES CLASIFICADORES")
    print("="*60)

    for name, model in models_to_test.items():
        print(f"\nEntrenando y evaluando: {name}")
        start_time = time.time()
        try:
            # Ensure training only if there's data
            if X_train.shape[0] > 0:
                model.fit(X_train, y_train)

                # Ensure test data exists before predicting
                if X_test.shape[0] > 0:
                    y_pred = model.predict(X_test)
                    f1_w = f1_score(y_test, y_pred, average='weighted')
                    accuracy = accuracy_score(y_test, y_pred)

                    # Check if predict_proba is available and multiple classes exist for ROC-AUC
                    roc_auc = np.nan
                    if hasattr(model, 'predict_proba') and len(np.unique(y_test)) > 1 and model.predict_proba(X_test).shape[1] > 1:
                         try:
                             roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
                         except Exception as e:
                             print(f"Error calculating ROC-AUC for {name}: {e}")
                             roc_auc = np.nan
                    else:
                        print(f"Skipping ROC-AUC for {name}: predict_proba not available or single class.")


                    end_time = time.time()
                    results[name] = {
                        'F1 Weighted': f1_w,
                        'Accuracy': accuracy,
                        'ROC-AUC': roc_auc,
                        'Time': end_time - start_time
                    }
                    print(f"  F1 Weighted: {f1_w:.4f}")
                    print(f"  Accuracy: {accuracy:.4f}")
                    if not np.isnan(roc_auc):
                        print(f"  ROC-AUC: {roc_auc:.4f}")
                    print(f"  Tiempo: {results[name]['Time']:.2f}s")
                else:
                     print("  Skipping evaluation: Test data is empty.")
                     end_time = time.time()
                     results[name] = {'F1 Weighted': np.nan, 'Accuracy': np.nan, 'ROC-AUC': np.nan, 'Time': end_time - start_time}
            else:
                print("  Skipping training: Training data is empty.")
                results[name] = {'F1 Weighted': np.nan, 'Accuracy': np.nan, 'ROC-AUC': np.nan, 'Time': 0}


        except Exception as e:
            print(f"Error durante entrenamiento/evaluaci√≥n de {name}: {e}")
            end_time = time.time()
            results[name] = {'F1 Weighted': np.nan, 'Accuracy': np.nan, 'ROC-AUC': np.nan, 'Time': end_time - start_time, 'Error': str(e)}

    results_df = pd.DataFrame(results).T
    print("\nResumen de resultados:")
    print(results_df)

    return results_df

# Ejecutar comparaci√≥n de modelos
comparison_results = compare_multiple_models(X_train_balanced, y_train_balanced, X_test, y_test)